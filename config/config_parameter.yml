hyperparams_input:
  img_width_imagenet: 224
  img_height_imagenet: 224
  img_width_cifar10: 32
  img_height_cifar10: 32
  img_width_mnist: 28
  img_height_mnist: 28
  num_channel_rgb: 3
  num_channel_bw: 1
  num_class_imagenet: 1000
  num_class_cifar10: 10
  num_class_mnist: 10

hyperparams_single_train:
  num_epoch: 1
  random_seed: 10000
  model_type: resnet
  activation: relu
  optimizer: Adam
  batch_size: 32
  num_model_layer: 50
  learning_rate: 0.01
  train_dataset: cifar10
  use_cpu: False
  use_tb_timeline: False

hyperparams_multiple_train:
  num_epoch: 1
  random_seed: 10000
  model_type:
    - mobilenet
    - mobilenet
  # activation: sigmoid, leaky_relu, tanh, relu
  activation:
    - relu
    - relu
  # optimizers: Adam, SGD, Adagrad, Momentum
  optimizer:
    - Adam
    - SGD
  num_model_layer:
    - 1
    - 1
  # if batch size are not all same, make batch_padding True
  batch_size:
    - 32
    - 32
  learning_rate:
    - 0.00001
    - 0.00001
  train_dataset: cifar10
  batch_padding: False
  use_cpu: False
  same_input: True
  use_tb_timeline: False
